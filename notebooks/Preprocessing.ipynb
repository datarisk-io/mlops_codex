{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOpsPreprocessing\n",
    "\n",
    "This notebook give a exemple on how to use MLOps to deploy a preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:37:12.696806Z",
     "start_time": "2025-01-29T15:37:12.560943Z"
    }
   },
   "source": [
    "from mlops_codex.preprocessing import MLOpsPreprocessingClient\n",
    "from mlops_codex.model import MLOpsModelClient"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOpsPreprocessingClient"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:37:19.209237Z",
     "start_time": "2025-01-29T15:37:15.439127Z"
    }
   },
   "source": "client = MLOpsPreprocessingClient()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sync pre processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:37:20.331768Z",
     "start_time": "2025-01-29T15:37:20.327165Z"
    }
   },
   "source": [
    "PATH = './samples/syncPreprocessing/'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:38:54.916199Z",
     "start_time": "2025-01-29T15:37:20.998510Z"
    }
   },
   "source": [
    "sync_preprocessing = client.create(\n",
    "    preprocessing_name='Teste preprocessing Sync', # model_name\n",
    "    preprocessing_reference='process', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    schema=PATH+'schema.json', # Path of the schema file, but it could be a dict (only required for Sync models)\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    operation=\"Sync\", # Can be Sync or Async\n",
    "    group='groupname' # Model group (create one using the client)\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: __upload_preprocessing Script was registered! - Hash: \"S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81\" with response {\"Hash\":\"S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81\",\"Message\":\"Script was registered!\"}\n",
      "January 29, 2025 | INFO: __host_preprocessing Preprocessing host in process - Hash: S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81\n",
      "January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "Waiting for deploy to be ready.January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      ".January 29, 2025 | INFO: get_preprocessing Preprocessing S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 its deployed. Fetching preprocessing.\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: handle_common_errors Preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 not found.\n",
      "January 29, 2025 | ERROR: handle_common_errors Preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 not found.\n",
      "January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 hash.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sync_preprocessing.set_token('29d9d82e09bb4c11b9cd4ce4e36e6c58')"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:40:40.975020Z",
     "start_time": "2025-01-29T15:40:40.853624Z"
    }
   },
   "source": [
    "result = sync_preprocessing.run(\n",
    "    data={'variable' : 100}\n",
    ")\n",
    "result"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: handle_common_errors Preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 not found.\n",
      "January 29, 2025 | ERROR: handle_common_errors Preprocessing hash S060050b11fe4022a2dc6b8cfd61d1bb2bbb7b6dfa41430b8a41c66b7dbbca81 not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_radius': 1000,\n",
       " 'mean_texture': 0,\n",
       " 'mean_perimeter': 0,\n",
       " 'mean_area': 0,\n",
       " 'mean_smoothness': 0,\n",
       " 'mean_compactness': 0,\n",
       " 'mean_concavity': 0,\n",
       " 'mean_concave_points': 0,\n",
       " 'mean_symmetry': 0,\n",
       " 'mean_fractal_dimension': 0,\n",
       " 'radius_error': 0,\n",
       " 'texture_error': 0,\n",
       " 'perimeter_error': 0,\n",
       " 'area_error': 0,\n",
       " 'smoothness_error': 0,\n",
       " 'compactness_error': 0,\n",
       " 'concavity_error': 0,\n",
       " 'concave_points_error': 0,\n",
       " 'symmetry_error': 0,\n",
       " 'fractal_dimension_error': 0,\n",
       " 'worst_radius': 0,\n",
       " 'worst_texture': 0,\n",
       " 'worst_perimeter': 0,\n",
       " 'worst_area': 0,\n",
       " 'worst_smoothness': 0,\n",
       " 'worst_compactness': 0,\n",
       " 'worst_concavity': 0,\n",
       " 'worst_concave_points': 0,\n",
       " 'worst_symmetry': 0,\n",
       " 'worst_fractal_dimension': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating async pre processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T15:53:36.631038Z",
     "start_time": "2025-01-29T15:50:29.261178Z"
    }
   },
   "source": [
    "PATH = './samples/asyncPreprocessing/'\n",
    "\n",
    "async_preprocessing = client.create(\n",
    "    preprocessing_name='Teste preprocessing Async', # preprocessing_name\n",
    "    preprocessing_reference='build_df', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    # env=PATH+'.env',  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'input.csv'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    schema=PATH+'schema.csv',\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    operation=\"Async\", # Can be Sync or Async\n",
    "    group='groupname', # Model group (create one using the client)\n",
    "    input_type='csv',\n",
    "    wait_for_ready=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: __upload_preprocessing Script was registered! - Hash: \"S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93\" with response {\"Hash\":\"S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93\",\"Message\":\"Script was registered!\"}\n",
      "January 29, 2025 | INFO: __host_preprocessing Preprocessing host in process - Hash: S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93\n",
      "January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "Waiting for deploy to be ready.January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      ".January 29, 2025 | INFO: get_preprocessing Preprocessing S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 its deployed. Fetching preprocessing.\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: handle_common_errors Preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 not found.\n",
      "January 29, 2025 | ERROR: handle_common_errors Preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 not found.\n",
      "January 29, 2025 | INFO: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n",
      "January 29, 2025 | ERROR: handle_common_errors Failed get status for preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 hash.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:29:23.032422Z",
     "start_time": "2025-01-29T16:29:23.028837Z"
    }
   },
   "source": "async_preprocessing.set_token('29d9d82e09bb4c11b9cd4ce4e36e6c58')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: set_token Token for group datarisk added.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:36:57.693819Z",
     "start_time": "2025-01-29T16:34:32.211747Z"
    }
   },
   "source": [
    "execution = async_preprocessing.run(data=PATH+'input.csv')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: handle_common_errors Preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 not found.\n",
      "January 29, 2025 | ERROR: handle_common_errors Preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 not found.\n",
      "January 29, 2025 | INFO: run Execution '7' started to generate 'Dc39fce439a546a999be185115e2507acfbb4ae76c3b4e428953584352e6a559'. Use the id to check its status.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPreprocessingError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/preprocessing.py:1296\u001B[0m, in \u001B[0;36mMLOpsPreprocessing.run\u001B[0;34m(self, data, group_token, wait_complete)\u001B[0m\n\u001B[1;32m   1295\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1296\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__new_preprocess_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdescribe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocessing_script_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocessing_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1297\u001B[0m     execution_id \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumOfExecutions\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/preprocessing.py:857\u001B[0m, in \u001B[0;36mMLOpsPreprocessingAsyncV2Client.describe\u001B[0;34m(self, preprocessing_script_hash)\u001B[0m\n\u001B[1;32m    855\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpreprocessing_script_hash\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 857\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mmake_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m    \u001B[49m\u001B[43msuccess_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPreprocessingError\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_exception_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPreprocessing hash \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpreprocessing_script_hash\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m not found.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger_msg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPreprocessing hash \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpreprocessing_script_hash\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m not found.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspecific_error_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m404\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAuthorization\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBearer \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtoken\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNeomaril-Origin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCodex\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNeomaril-Method\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdescribe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__qualname__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/http_request_handler.py:149\u001B[0m, in \u001B[0;36mmake_request\u001B[0;34m(url, method, success_code, custom_exception, custom_exception_message, specific_error_code, logger_msg, headers, params, data, json, files, timeout)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[0;32m--> 149\u001B[0m \u001B[43mhandle_common_errors\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspecific_error_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_exception\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_exception_message\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger_msg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/http_request_handler.py:89\u001B[0m, in \u001B[0;36mhandle_common_errors\u001B[0;34m(response, specific_error_code, custom_exception, custom_exception_message, logger_msg)\u001B[0m\n\u001B[1;32m     88\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(response\u001B[38;5;241m.\u001B[39mjson())\n\u001B[0;32m---> 89\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m custom_exception(custom_exception_message)\n\u001B[1;32m     91\u001B[0m formatted_msg \u001B[38;5;241m=\u001B[39m parse_json_to_yaml(response\u001B[38;5;241m.\u001B[39mjson())\n",
      "\u001B[0;31mPreprocessingError\u001B[0m: Preprocessing hash S58671145d72475b9f8930ce1a8ade4fd9886434d07d498eb02f50591eb12e93 not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m execution \u001B[38;5;241m=\u001B[39m \u001B[43masync_preprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPATH\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/preprocessing.py:1342\u001B[0m, in \u001B[0;36mMLOpsPreprocessing.run\u001B[0;34m(self, data, group_token, wait_complete)\u001B[0m\n\u001B[1;32m   1340\u001B[0m message \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m   1341\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(message[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMessage\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m-> 1342\u001B[0m exec_id \u001B[38;5;241m=\u001B[39m \u001B[43mmessage\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecutionId\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1343\u001B[0m run \u001B[38;5;241m=\u001B[39m MLOpsExecution(\n\u001B[1;32m   1344\u001B[0m     parent_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessing_id,\n\u001B[1;32m   1345\u001B[0m     exec_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncPreprocessing\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1351\u001B[0m     group_token\u001B[38;5;241m=\u001B[39mgroup_token,\n\u001B[1;32m   1352\u001B[0m )\n\u001B[1;32m   1353\u001B[0m response \u001B[38;5;241m=\u001B[39m run\u001B[38;5;241m.\u001B[39mget_status()\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/preprocessing.py:1342\u001B[0m, in \u001B[0;36mMLOpsPreprocessing.run\u001B[0;34m(self, data, group_token, wait_complete)\u001B[0m\n\u001B[1;32m   1340\u001B[0m message \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m   1341\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(message[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMessage\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m-> 1342\u001B[0m exec_id \u001B[38;5;241m=\u001B[39m \u001B[43mmessage\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecutionId\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1343\u001B[0m run \u001B[38;5;241m=\u001B[39m MLOpsExecution(\n\u001B[1;32m   1344\u001B[0m     parent_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessing_id,\n\u001B[1;32m   1345\u001B[0m     exec_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncPreprocessing\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1351\u001B[0m     group_token\u001B[38;5;241m=\u001B[39mgroup_token,\n\u001B[1;32m   1352\u001B[0m )\n\u001B[1;32m   1353\u001B[0m response \u001B[38;5;241m=\u001B[39m run\u001B[38;5;241m.\u001B[39mget_status()\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:34:24.083718667Z",
     "start_time": "2025-01-29T16:32:31.503495Z"
    }
   },
   "source": [
    "execution.get_status()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '6',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': '[/app/store/datarisk/datasets/D71a7cfa1e9344009a2e2c2427fb28a70b1bf3eefd754173a8fac04e08c4a395/processed_data.parquet]'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:34:24.027410Z",
     "start_time": "2025-01-29T16:32:52.483944Z"
    }
   },
   "source": [
    "execution.wait_ready()\n",
    "execution.download_result()"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# execution.wait_ready()\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mexecution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/mlops_codex/src/mlops_codex/base.py:576\u001B[0m, in \u001B[0;36mMLOpsExecution.download_result\u001B[0;34m(self, path, filename)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ModelExecutionState\u001B[38;5;241m.\u001B[39mSucceeded:\n\u001B[1;32m    573\u001B[0m     url \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    574\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__url_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/result/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexec_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    575\u001B[0m     )\n\u001B[0;32m--> 576\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAuthorization\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBearer \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNeomaril-Origin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCodex\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNeomaril-Method\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__qualname__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m410\u001B[39m]:\n\u001B[1;32m    585\u001B[0m         formatted_msg \u001B[38;5;241m=\u001B[39m parse_json_to_yaml(response\u001B[38;5;241m.\u001B[39mjson())\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/urllib3/connectionpool.py:493\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    490\u001B[0m \u001B[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001B[39;00m\n\u001B[1;32m    491\u001B[0m \u001B[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001B[39;00m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 493\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43menforce_content_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menforce_content_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBrokenPipeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/urllib3/connection.py:444\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mputheader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m, _get_default_user_agent())\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m header, value \u001B[38;5;129;01min\u001B[39;00m headers\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mputheader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendheaders()\n\u001B[1;32m    447\u001B[0m \u001B[38;5;66;03m# If we're given a body we start sending that in chunks.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/mlops-neomaril-codex-48dADUmW/lib/python3.10/site-packages/urllib3/connection.py:355\u001B[0m, in \u001B[0;36mHTTPConnection.putheader\u001B[0;34m(self, header, *values)\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    348\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMethod cannot contain non-token characters \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmethod\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m (found at least \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmatch\u001B[38;5;241m.\u001B[39mgroup()\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    349\u001B[0m         )\n\u001B[1;32m    351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mputrequest(\n\u001B[1;32m    352\u001B[0m         method, url, skip_host\u001B[38;5;241m=\u001B[39mskip_host, skip_accept_encoding\u001B[38;5;241m=\u001B[39mskip_accept_encoding\n\u001B[1;32m    353\u001B[0m     )\n\u001B[0;32m--> 355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mputheader\u001B[39m(\u001B[38;5;28mself\u001B[39m, header: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39mvalues: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m v \u001B[38;5;241m==\u001B[39m SKIP_HEADER \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access created pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = client.get_preprocessing(preprocessing_id='Sa79236b3dfc4f22a502e816a07dab382cee6327a5334c5bbba13c456233b8c4', group='groupname')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access created executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_execution = async_preprocessing.get_preprocessing_execution(exec_id='2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execution_4.download_result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using preprocessing with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = MLOpsModelClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sync Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_model = model_client.get_model(group='groupname', model_id='M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91')\n",
    "\n",
    "sync_model.set_token('29d9d82e09bb4c11b9cd4ce4e36e6c58')\n",
    "\n",
    "data = {\n",
    " \"mean_radius\": 17.99,\n",
    " \"mean_texture\": 10.38,\n",
    " \"mean_perimeter\": 122.8,\n",
    " \"mean_area\": 1001.0,\n",
    " \"mean_smoothness\": 0.1184,\n",
    " \"mean_compactness\": 0.2776,\n",
    " \"mean_concavity\": 0.3001,\n",
    " \"mean_concave_points\": 0.1471,\n",
    " \"mean_symmetry\": 0.2419,\n",
    " \"mean_fractal_dimension\": 0.07871,\n",
    " \"radius_error\": 1.095,\n",
    " \"texture_error\": 0.9053,\n",
    " \"perimeter_error\": 8.589,\n",
    " \"area_error\": 153.4,\n",
    " \"smoothness_error\": 0.006399,\n",
    " \"compactness_error\": 0.04904,\n",
    " \"concavity_error\": 0.05373,\n",
    " \"concave_points_error\": 0.01587,\n",
    " \"symmetry_error\": 0.03003,\n",
    " \"fractal_dimension_error\": 0.006193,\n",
    " \"worst_radius\": 25.38,\n",
    " \"worst_texture\": 17.33,\n",
    " \"worst_perimeter\": 184.6,\n",
    " \"worst_area\": 2019.0,\n",
    " \"worst_smoothness\": 0.1622,\n",
    " \"worst_compactness\": 0.6656,\n",
    " \"worst_concavity\": 0.7119,\n",
    " \"worst_concave_points\": 0.2654,\n",
    " \"worst_symmetry\": 0.4601,\n",
    " \"worst_fractal_dimension\": 0.1189\n",
    "}\n",
    "\n",
    "sync_model.predict(data=data, preprocessing=sync_preprocessing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_model = model_client.get_model(group='groupname', model_id='Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3')\n",
    "\n",
    "PATH = './samples/asyncModel/'\n",
    "\n",
    "async_model.set_token('29d9d82e09bb4c11b9cd4ce4e36e6c58')\n",
    "\n",
    "execution = async_model.predict(data=PATH+'input.csv', preprocessing=async_preprocessing)\n",
    "execution.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.download_result()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "-----"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## New preprocessing\n",
    "\n",
    "We're rebuilding the process module. The main feature is the end multiples datasets to MLOps server. Check the code below"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:44:46.582124Z",
     "start_time": "2025-01-29T16:41:31.006017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PATH = \"./samples/asyncPreprocessingMultiple/\"\n",
    "\n",
    "schemas = [\n",
    "    (\"base_cadastral\", PATH+'base_cadastral.csv'),\n",
    "    (\"base_pagamentos\", PATH+'base_pagamentos.csv'),\n",
    "    (\"base_info\", PATH+'base_info.csv'),\n",
    "]\n",
    "\n",
    "preprocess = client.create(\n",
    "    preprocessing_name='test_preprocessing', # model_name\n",
    "    preprocessing_reference='build_df', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file,\n",
    "    schema=schemas, # Path of the schema file, but it could be a dict (only required for Sync models)\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    operation=\"Async\", # Can be Sync or Async\n",
    "    group='groupname', # Model group (create one using the client)\n",
    "    wait_for_ready=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 29, 2025 | INFO: create Creating preprocessing for preprocessing hash\n",
      " Preprocessing hash = S66b0c6caa524f74829a1af9d6015e1e9d7df0bddf4a4e60b515aaac201ab4a0\n",
      "January 29, 2025 | INFO: create Created dataset hash D83813d67d2c4c68afd340585650dca4f8d46846c1e048dd8af7be9d0d1548c0 with name base_cadastral\n",
      "January 29, 2025 | INFO: create Created dataset hash D89d8a9c251a461d82dddecd31a9b3a9c5107cdc2c0b4c4d99b010f9d8d6c4e0 with name base_pagamentos\n",
      "January 29, 2025 | INFO: create Created dataset hash D60dfe4564ad462389a675d25ce32487b36b6e6745024b40ae61b57a838c1088 with name base_info\n",
      "January 29, 2025 | INFO: create Schema files uploaded\n",
      "January 29, 2025 | INFO: create Script file uploaded\n",
      "January 29, 2025 | INFO: create Requirements file uploaded\n",
      "January 29, 2025 | INFO: create Hosting preprocessing script\n",
      "Waiting for preprocessing script to finish.....January 29, 2025 | INFO: wait \n",
      "Preprocessing script finished successfully\n",
      "January 29, 2025 | INFO: create Successfully hosted preprocessing script\n",
      "January 29, 2025 | INFO: get_preprocessing Preprocessing S66b0c6caa524f74829a1af9d6015e1e9d7df0bddf4a4e60b515aaac201ab4a0 its deployed. Fetching preprocessing.\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n",
      "January 29, 2025 | INFO: __init__ Loading .env\n",
      "January 29, 2025 | INFO: __init__ Successfully connected to MLOps\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:01:47.653615Z",
     "start_time": "2025-01-27T20:00:18.728989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = [\n",
    "    (\"base_cadastral\", PATH+'base_cadastral.csv'),\n",
    "    (\"base_pagamentos\", PATH+'base_pagamentos.csv'),\n",
    "    (\"base_info\", PATH+'base_info.csv'),\n",
    "]\n",
    "\n",
    "run = preprocess.run(\n",
    "    data=inputs,\n",
    "    wait_complete=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 27, 2025 | INFO: register_execution Registered execution for preprocessing hash Sabf4c60b7a54759bf205e3eb3325e55deabf943a6a54b8cbf23557e60bfd937\n",
      " Message = Preprocess Execution '16' created\n",
      "January 27, 2025 | INFO: run Preprocessing script execution Sabf4c60b7a54759bf205e3eb3325e55deabf943a6a54b8cbf23557e60bfd937 is registered. Execution ID = 16\n",
      "January 27, 2025 | INFO: run Uploaded input file ('base_cadastral', './samples/asyncPreprocessingMultiple/base_cadastral.csv') - Output Hash D17861f1574f419a9350185dc01dd1658cd932d271234f8e98407ead4834311a\n",
      "January 27, 2025 | INFO: run Uploaded input file ('base_pagamentos', './samples/asyncPreprocessingMultiple/base_pagamentos.csv') - Output Hash De1f49c6b5b84d1d9a42bc144d2948a5b87cd849bb8449d792b16c3a90112889\n",
      "January 27, 2025 | INFO: run Uploaded input file ('base_info', './samples/asyncPreprocessingMultiple/base_info.csv') - Output Hash D7e77efaa50e4eda9293be071dada3115038a38638f04f5b93e3e3d5c64ecbf1\n",
      "January 27, 2025 | INFO: run Started preprocessing script execution 16 - Hash Sabf4c60b7a54759bf205e3eb3325e55deabf943a6a54b8cbf23557e60bfd937\n",
      "Waiting for preprocessing script to finish..January 27, 2025 | INFO: __wait_for_execution Preprocessing script finished successfully\n",
      "January 27, 2025 | INFO: run Script finished successfully. Consider downloading the results using the 'download()' method.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "run.download()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-neomaril-codex-c4z0dHNl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
