{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Training\n",
    "\n",
    "This notebook give a exemple on how to use MLOps to training a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLOpsTrainingClient\n",
    "\n",
    "It's where you can manage your trainining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T12:28:38.913416Z",
     "start_time": "2024-08-27T12:28:38.470234Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlops_codex.training import MLOpsTrainingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:58.562764Z",
     "start_time": "2024-08-27T13:18:40.119319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "\n",
    "client = MLOpsTrainingClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOpsTrainingExperiment\n",
    "\n",
    "It's where you can create a training experiment to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training\n",
    "\n",
    "With Custom training, you have to create the training function. For you, as a data scientist, it's common to re-run the entire notebook, over and over. To avoid creating the same experiment repeatedly, the `force = False` parameter will disallow it. If you wish to create a new experiment with the same attributes, turn `force = True`.\n",
    "\n",
    "If you have two equal experiments and pass `force = False`, the first created experiment will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment(\n",
    "    experiment_name='Teste notebook',   # Experiment name, this is how you find your model in MLFLow\n",
    "    model_type='Classification',        # Model type. Can be Classification, Regression or Unsupervised\n",
    "    group='test1',                  # This is the default group. Create a new one when using for a new project,\n",
    "    # force=True                        # Forces to create a new experiment with the same attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the experiment class we can create multiple model runs\n",
    "PATH = './samples/train/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test', # Run name\n",
    "    train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    training_reference='train_model', # The name of the entrypoint function that is going to be called inside the source file \n",
    "    training_type='Custom',\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.execution_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the run is finished you can download the model file\n",
    "run.download_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or promote promete it to a deployed model\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model(\n",
    "    model_name='Teste notebook promoted custom', # model_name\n",
    "    model_reference='score', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    schema=PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    operation=\"Sync\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML\n",
    "\n",
    "With AutoML you just need to upload the data and some configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './samples/autoML/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test', # Run name\n",
    "    training_type='AutoML',\n",
    "    train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "    conf_dict=PATH+'conf.json', # Path of the configuration file\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote a AutoML model is a lot easier\n",
    "\n",
    "PATH = './samples/autoML/'\n",
    "MODEL_PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model(\n",
    "    model_name='Teste notebook promoted autoML', # model_name\n",
    "    operation=\"Async\", # Can be Sync or Async,\n",
    "    input_type=\"json\",\n",
    "    schema=PATH+'schema.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Complete flow in MLOps\n",
    "\n",
    "In this next cells, you'll learn how to use the MLOPs platform from end-to-end"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import and load training and preprocessing clients"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mlops_codex.preprocessing import MLOpsPreprocessingClient\n",
    "from mlops_codex.training import MLOpsTrainingClient\n",
    "\n",
    "t_client = MLOpsTrainingClient()\n",
    "\n",
    "p_client = MLOpsPreprocessingClient()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a new training experiment"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Creating a new training experiment\n",
    "training = t_client.create_training_experiment(\n",
    "    experiment_name='Teste notebook',\n",
    "    model_type='Classification',\n",
    "    group='<insert_group>',\n",
    ")\n",
    "\n",
    "PATH = './samples/completeFlow/customTrain/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test',\n",
    "    train_data=PATH+'base_completa.parquet',\n",
    "    source_file=PATH+'app.py',\n",
    "    requirements_file=PATH+'requirements.txt',\n",
    "    training_reference='train_model',\n",
    "    training_type='Custom',\n",
    "    python_version='3.9',\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Promote the experiment to a model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PATH = './samples/completeFlow/model/'\n",
    "\n",
    "model = run.promote_model(\n",
    "    model_name='Teste notebook promoted custom',\n",
    "    model_reference='score',\n",
    "    source_file=PATH+'app.py',\n",
    "    schema=PATH+'schema.parquet',\n",
    "    operation=\"Async\",\n",
    "    input_type=\"parquet\",\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.set_token(\"TOKEN\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.get_logs()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.info()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a new preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PATH = \"./samples/asyncPreprocessingMultiple/\"\n",
    "\n",
    "schemas = [\n",
    "    (\"base_cadastral\", PATH+'base_cadastral.csv'),\n",
    "    (\"base_pagamentos\", PATH+'base_pagamentos.csv'),\n",
    "    (\"base_info\", PATH+'base_info.csv'),\n",
    "]\n",
    "\n",
    "preprocess = p_client.create(\n",
    "    preprocessing_name='test_preprocessing',\n",
    "    preprocessing_reference='build_df',\n",
    "    source_file=PATH+'app.py',\n",
    "    requirements_file=PATH+'requirements.txt',\n",
    "    schema=schemas,\n",
    "    python_version='3.9',\n",
    "    operation=\"Async\",\n",
    "    group='<insert_group>',\n",
    "    wait_complete=True\n",
    "\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can predict your data using preprocessed data. If you do it, a preprocessed dataset will be automatically installed on your computer. It will be called `preprocessed_data.parquet`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "execution1 = model.predict(\n",
    "    data=schemas,\n",
    "    preprocessing=preprocess,\n",
    "    group_token=\"TOKEN\",\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, you can predict data directly, without a preprocessing:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PATH = \"./samples/completeFlow/model/\"\n",
    "execution2 = model.predict(\n",
    "    data=PATH + \"input.parquet\"\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.execution_info(execution_id=1)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After aprove your model, register a monitoring"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PATH = \"./samples/completeFlow/monitoring/\"\n",
    "model.register_monitoring(\n",
    "    preprocess_reference=\"build_df\",\n",
    "    shap_reference=\"get_shap\",\n",
    "    configuration_file=PATH+\"configuration.json\",\n",
    "    preprocess_file=PATH+\"preprocess_async.py\",\n",
    "    wait_complete=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-neomaril-codex-c4z0dHNl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
