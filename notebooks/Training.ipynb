{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77559178",
   "metadata": {},
   "source": [
    "# MLOps Training\n",
    "\n",
    "This notebook give a exemple on how to use MLOps to training a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9b0da",
   "metadata": {},
   "source": [
    "### MLOpsTrainingClient\n",
    "\n",
    "It's where you can manage your trainining experiments"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "from mlops_codex.training import MLOpsTrainingClient",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f47d2a5a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Initializing the MLOpsTrainingClient\n",
    "In this cell, we are initializing the `MLOpsTrainingClient` which will be used to manage our training experiments."
   ]
  },
  {
   "cell_type": "code",
   "id": "556a3fb73290a75b",
   "metadata": {},
   "source": "client = MLOpsTrainingClient()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "deb3a4c9",
   "metadata": {},
   "source": [
    "## MLOpsTrainingExperiment\n",
    "\n",
    "It's where you can create a training experiment to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09074b27",
   "metadata": {},
   "source": [
    "#### Custom training\n",
    "\n",
    "With Custom training, you have to create the training function. For you, as a data scientist, it's common to re-run the entire notebook, over and over. To avoid creating the same experiment repeatedly, the `force = False` parameter will disallow it. If you wish to create a new experiment with the same attributes, turn `force = True`.\n",
    "\n",
    "If you have two equal experiments and pass `force = False`, the first created experiment will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "id": "a8f129be78149bb1",
   "metadata": {},
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment(\n",
    "    experiment_name='experiment2',\n",
    "    model_type='Classification',\n",
    "    group='<group>',\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be81cf47890e1e6a",
   "metadata": {},
   "source": [
    "training"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7a4107da1c07f9",
   "metadata": {},
   "source": [
    "# With the experiment class we can create multiple model runs\n",
    "PATH = './samples/completeFlow/customTrain/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test',\n",
    "    training_type='Custom',\n",
    "    train_data=PATH + 'base_completa.parquet',\n",
    "    requirements_file=PATH + 'requirements.txt',\n",
    "    source_file=PATH + 'app.py',\n",
    "    python_version='3.10',\n",
    "    training_reference='train_model',\n",
    "    wait_complete=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a83032179dcb070",
   "metadata": {},
   "source": [
    "run.status"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c9162e4384c578a",
   "metadata": {},
   "source": [
    "run.execution_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b55fb7e4ad997e8",
   "metadata": {},
   "source": [
    "### Promote training"
   ]
  },
  {
   "cell_type": "code",
   "id": "61bd54e3b648fdfd",
   "metadata": {},
   "source": [
    "PATH = './samples/completeFlow/model/'\n",
    "model = run.promote_model(\n",
    "    source_file=PATH + 'app.py',\n",
    "    schema=PATH + 'schema.parquet',\n",
    "    operation=\"Async\",\n",
    "    model_name=\"AsyncModel\",\n",
    "    input_type=\".parquet\",\n",
    "    model_reference=\"score\",\n",
    "    wait_complete=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "id": "356c58bb6a6d5c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PATH = './samples/completeFlow/monitoring/'\n",
    "\n",
    "model.register_monitoring(\n",
    "    preprocess_reference='build_df',\n",
    "    shap_reference='get_shap',\n",
    "    configuration_file=PATH + 'configuration.json',\n",
    "    preprocess_file=PATH + 'preprocess_async.py',\n",
    ")"
   ],
   "id": "5158b7eb3184a678",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "daedbd49",
   "metadata": {},
   "source": [
    "#### AutoML\n",
    "\n",
    "With AutoML you just need to upload the data and some configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "816f785a26dcf617",
   "metadata": {},
   "source": [
    "PATH = './samples/autoML/'\n",
    "\n",
    "run2 = training.run_training(\n",
    "    run_name='First test',\n",
    "    training_type='AutoML',\n",
    "    conf_dict=PATH + \"conf.json\",\n",
    "    train_data=PATH + 'dados.csv',\n",
    "    wait_complete=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44281a357e0028c6",
   "metadata": {},
   "source": [
    "#### External Training\n",
    "\n",
    "Besides the autoML and custom training, you can perform a training on your own machine and upload the files!\n",
    "\n",
    "Look the example bellow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad876be96a8213ab",
   "metadata": {},
   "source": [
    "PATH = './samples/externalUpload/'\n",
    "\n",
    "run3 = training.run_training(\n",
    "    run_name='First test',\n",
    "    training_type=\"External\",\n",
    "    X_train=PATH + 'features.parquet',\n",
    "    y_train=PATH + 'target.parquet',\n",
    "    model_outputs=PATH + 'predictions.parquet',\n",
    "    model_metrics=PATH + 'metrics.json',\n",
    "    model_params=PATH + 'params.json',\n",
    "    requirements_file=PATH + 'requirements.txt',\n",
    "    model_file=PATH + 'model.pkl',\n",
    "    python_version=\"3.9\",\n",
    "    wait_complete=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21dbdbe6a258990c",
   "metadata": {},
   "source": [
    "run3.status"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f55fe0a26c5c2221",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Interactive External Training\n",
    "\n",
    "However, if you wish something more interactive, take a look in the example bellow."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d8b38fedf20383b",
   "metadata": {},
   "source": [
    "from mlops_codex.training import MLOpsTrainingClient\n",
    "client = MLOpsTrainingClient()\n",
    "training = client.create_training_experiment(\n",
    "    experiment_name='Teste',\n",
    "    model_type='Classification',\n",
    "    group='<group>'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "764cec758141737c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b22680b507344617",
   "metadata": {},
   "source": [
    "base_path = './samples/train/'\n",
    "df = pd.read_csv(base_path+\"/dados.csv\")\n",
    "X = df.drop(columns=['target'])\n",
    "y = df[[\"target\"]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3200db0515a2b3c3",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df[\"mean_radius\"], df[\"mean_texture\"])\n",
    "\n",
    "# Configurar o título do gráfico\n",
    "plt.title(\"Relação entre mean_radius e mean_texture\")\n",
    "\n",
    "# Configurar os rótulos dos eixos\n",
    "plt.xlabel(\"mean_radius\")\n",
    "plt.ylabel(\"mean_texture\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d748960244448dad",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(SimpleImputer(), LGBMClassifier(force_col_wise=True))\n",
    "pipe.fit(X, y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7dbcffb925124081",
   "metadata": {},
   "source": [
    "with training.log_train(name='Teste 2', X_train=X, y_train=y) as logger:\n",
    "    logger.save_model(pipe)\n",
    "\n",
    "    model_output = pd.DataFrame({\"pred\": pipe.predict(X), \"proba\": pipe.predict_proba(X)[:,1]})\n",
    "\n",
    "    logger.save_model_output(model_output)\n",
    "\n",
    "    logger.save_plot(fig=fig, filename=\"test-image\")\n",
    "\n",
    "    auc = cross_val_score(pipe, X, y, cv=5, scoring=\"roc_auc\")\n",
    "    f_score = cross_val_score(pipe, X, y, cv=5, scoring=\"f1\")\n",
    "    logger.save_metric(name='auc', value=auc.mean())\n",
    "    logger.save_metric(name='f1_score', value=f_score.mean())\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
